{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Praktikum 2, Monte Carlo\n",
    "## Math modeling of the atmosphere\n",
    "\n",
    "\n",
    "## Computing average autoconversion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Autoconversion is the process by which small cloud droplets grow in size and become rain drops. It can be approximated as a function of two variables, $\\chi$ and $N_c$:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$A(\\chi, N_c)=H(\\chi){\\chi}^{\\alpha}{N_c}^{\\beta}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gamma, pbdv\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "def a_chi_n_c(chi, n_c, alpha, beta):\n",
    "    H = lambda x: 1 if x > 0 else 0\n",
    "    return np.nan_to_num(H(chi) * (chi ** alpha) * (n_c ** beta))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here $\\chi$ is related to clound water mixing ratio, and $N_c$ is the number of cloud droplets. The expontent $\\alpha$ is often taken to equal 2.47, and the exponent $\\beta$ is often taken to equal -1.79. Therefore, if there is more cloud water or larger drops, rain forms more easily."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "alpha = 2.47\n",
    "beta = -1.79"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we integrate over this autoconversion expression over a bivariate PDF that is normal in $\\chi$ and lognormal in $N_c$, we find"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Write a python function that computes the exact average autoconversion rate given by the formula above. As input, it should take in the means, standard deviations, and correlation of the PDF, along with the exponents $\\alpha$ and $\\beta$. As output, it should produce $\\overline{A(\\chi,N_c)}$. Use the `scipy.special` function, `pbdv`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "def exact_average_autoconversion_rate(my_n_c, my_chi,\n",
    "                                      sigma_chi, sigma_n_c,\n",
    "                                      r_chi_n_c, alpha, beta):\n",
    "    return (1 / (np.sqrt(2 * np.pi))) * (sigma_chi ** alpha) * np.exp((my_n_c * beta) + ((1 / 2) * sigma_n_c ** 2 * beta ** 2) - ((1 / 4) * ((my_chi / sigma_chi) + r_chi_n_c * sigma_n_c * beta) ** 2)) * gamma(alpha + 1) * pbdv(-(alpha + 1), -((my_chi / sigma_chi) + r_chi_n_c * sigma_n_c * beta))[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. To represent the $\\chi$ distribution, create a sample from a univariate uniform distribution and transform it to a standard normal. To represent the $N_c$ distribution, create another, independent sample from a univariate standard normal. Together, these points form a sample from a bivariate,\n",
    "uncorrelated standard normal distribution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "def draw_from_uniform_dist(n: int):\n",
    "    from numpy import random\n",
    "    return random.uniform(size=n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "def transform_to_standard_normal(points):\n",
    "    from scipy.stats import norm\n",
    "    return norm.ppf(points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0178592303669873\n"
     ]
    }
   ],
   "source": [
    "print(exact_average_autoconversion_rate(0, 0, 1, 1, 0, alpha, beta))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09988328  0.39840286 -0.86270023 ... -1.28584038 -0.44179201\n",
      "   0.63379114]\n",
      " [ 0.42545568 -0.00659309  1.0461615  ...  1.07651282 -1.54532173\n",
      "  -0.49850614]]\n"
     ]
    }
   ],
   "source": [
    "num_points = 1000\n",
    "\n",
    "\n",
    "def create_chi_n_c(num_points: int):\n",
    "    chi = np.array(transform_to_standard_normal(draw_from_uniform_dist(num_points)))\n",
    "    n_c = np.array(transform_to_standard_normal(draw_from_uniform_dist(num_points)))\n",
    "    return np.array([chi, n_c])\n",
    "\n",
    "\n",
    "chi_n_c = create_chi_n_c(num_points)\n",
    "print(chi_n_c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Use a Cholesky decomposition in order to transform the distribution from a 2D uncorrelated standard normal to a 2D correlated normal. Assume a correlation $r_{(\\chi,N_c)n}$, a mean $N_c$ of $\\mu_{N_{cn}}$ , etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\Sigma = \\begin{bmatrix}\n",
    "        1 & r_{12} \\\\\n",
    "        r_{12} & 1\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "L = \\begin{bmatrix}\n",
    "    \\sigma_x & 0 \\\\\n",
    "    \\sigma_y * r_{12} & \\sigma_y\\sqrt{1-{r_{12}}^2}\n",
    "    \\end{bmatrix}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And the decomposition formular:\n",
    "$$ X = L \\cdot Y + \\mu $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def transform_to_correlated_by_cholesky(sigma_x, sigma_y, r_12, Y, my):\n",
    "    import numpy as np\n",
    "    L = np.array([[sigma_x, 0], [sigma_y * r_12, sigma_y * np.sqrt(1 - (r_12 ** 2))]])\n",
    "    return L.dot(Y) + my"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09988328  0.39840286 -0.86270023 ... -1.28584038 -0.44179201\n",
      "   0.63379114]\n",
      " [-0.0807612   0.39770968 -0.81506346 ... -1.23642346 -0.51044182\n",
      "   0.61086905]]\n"
     ]
    }
   ],
   "source": [
    "correlated_bivariate_dist = transform_to_correlated_by_cholesky(sigma_x=1, sigma_y=1, r_12=0.999, Y=chi_n_c, my=0)\n",
    "print(correlated_bivariate_dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. In order to transform to a lognormal distribution in $N_c$, take the exponential of the $N_c$ component of the sample points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09988328  0.39840286 -0.86270023 ... -1.28584038 -0.44179201\n",
      "   0.63379114]\n",
      " [ 0.92241394  1.48841185  0.44261124 ...  0.29042107  0.60023032\n",
      "   1.84203152]]\n"
     ]
    }
   ],
   "source": [
    "def lognormal_correlated_bivariate_dist(correlated_bivariate_dist):\n",
    "    return np.array([correlated_bivariate_dist[0].copy(), np.exp(correlated_bivariate_dist[1])])\n",
    "\n",
    "\n",
    "lognormal_correlated_bivariate_dist = lognormal_correlated_bivariate_dist(correlated_bivariate_dist)\n",
    "print(lognormal_correlated_bivariate_dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Use Monte Carlo integration in order to find the integral $\\overline{A(\\chi,N_c)}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sberg\\AppData\\Local\\Temp\\ipykernel_15372\\1634153696.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.nan_to_num(H(chi) * (chi ** alpha) * (n_c ** beta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.552588948192074\n",
      "2.2322959223688073\n"
     ]
    }
   ],
   "source": [
    "def A_chi_N_c_Monte_Carlo(lognormal_correlated_bivariate_dist,\n",
    "                          alpha=alpha, beta=beta):\n",
    "    return np.average(np.nan_to_num([a_chi_n_c(chi=c, n_c=nc, alpha=alpha, beta=beta) for c in lognormal_correlated_bivariate_dist[0] for nc in lognormal_correlated_bivariate_dist[1]]))\n",
    "\n",
    "\n",
    "print(A_chi_N_c_Monte_Carlo(lognormal_correlated_bivariate_dist, alpha, beta))\n",
    "print(exact_average_autoconversion_rate(1,1, 1, 1, 0, 2.47, -1.79))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Compute the Monte Carlo estimate for multiple values of N. Check whether your answer converges to the analytic answer as $\\frac{1}{\\sqrt{n}}$. Make sure that it converges for non-zero values of $r_{(\\chi,N_c)n}$. To improve the convergence rate, choose a value of $\\sigma_{N_{cn}} < 2$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[132], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_X\u001B[39m(num_points\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, sigma_x\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, sigma_y\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, r_12\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.99\u001B[39m, my\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lognormal_correlated_bivariate_dist(\n\u001B[0;32m      3\u001B[0m         transform_to_correlated_by_cholesky(sigma_x, sigma_y, r_12, create_chi_n_c(num_points), my))\n\u001B[1;32m----> 5\u001B[0m X\u001B[38;5;241m=\u001B[39m\u001B[43mgenerate_X\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_points\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(np\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m10_000\u001B[39m), A_chi_N_c_Monte_Carlo(X))\n",
      "Cell \u001B[1;32mIn[132], line 2\u001B[0m, in \u001B[0;36mgenerate_X\u001B[1;34m(num_points, sigma_x, sigma_y, r_12, my)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_X\u001B[39m(num_points\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, sigma_x\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, sigma_y\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, r_12\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.99\u001B[39m, my\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlognormal_correlated_bivariate_dist\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform_to_correlated_by_cholesky\u001B[49m\u001B[43m(\u001B[49m\u001B[43msigma_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr_12\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_chi_n_c\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_points\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmy\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "def generate_X(num_points=100, sigma_x=1, sigma_y=1, r_12=0.99, my=0):\n",
    "    return lognormal_correlated_bivariate_dist(\n",
    "        transform_to_correlated_by_cholesky(sigma_x, sigma_y, r_12, create_chi_n_c(num_points), my))\n",
    "\n",
    "X=generate_X(num_points=10000)\n",
    "plt.plot(np.linspace(0,10_000), A_chi_N_c_Monte_Carlo(X))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
